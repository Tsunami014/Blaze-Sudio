from _typeshed import Incomplete
from mlflow import pyfunc as pyfunc
from mlflow.exceptions import MlflowException as MlflowException
from mlflow.models import Model as Model, ModelSignature as ModelSignature
from mlflow.models.model import MLMODEL_FILE_NAME as MLMODEL_FILE_NAME
from mlflow.models.utils import ModelInputExample as ModelInputExample
from mlflow.protos.databricks_pb2 import RESOURCE_DOES_NOT_EXIST as RESOURCE_DOES_NOT_EXIST
from mlflow.tracking._model_registry import DEFAULT_AWAIT_MAX_SLEEP_SECONDS as DEFAULT_AWAIT_MAX_SLEEP_SECONDS
from mlflow.utils.annotations import experimental as experimental
from mlflow.utils.autologging_utils import autologging_integration as autologging_integration, safe_patch as safe_patch
from mlflow.utils.docstring_utils import LOG_MODEL_PARAM_DOCS as LOG_MODEL_PARAM_DOCS, format_docstring as format_docstring
from mlflow.utils.file_utils import TempDir as TempDir, write_to as write_to

FLAVOR_NAME: str

def get_default_pip_requirements(): ...
def get_default_conda_env(): ...
def log_model(pytorch_model, artifact_path, conda_env: Incomplete | None = None, code_paths: Incomplete | None = None, pickle_module: Incomplete | None = None, registered_model_name: Incomplete | None = None, signature: ModelSignature = None, input_example: ModelInputExample = None, await_registration_for=..., requirements_file: Incomplete | None = None, extra_files: Incomplete | None = None, pip_requirements: Incomplete | None = None, extra_pip_requirements: Incomplete | None = None, **kwargs): ...
def save_model(pytorch_model, path, conda_env: Incomplete | None = None, mlflow_model: Incomplete | None = None, code_paths: Incomplete | None = None, pickle_module: Incomplete | None = None, signature: ModelSignature = None, input_example: ModelInputExample = None, requirements_file: Incomplete | None = None, extra_files: Incomplete | None = None, pip_requirements: Incomplete | None = None, extra_pip_requirements: Incomplete | None = None, **kwargs): ...
def load_model(model_uri, dst_path: Incomplete | None = None, **kwargs): ...

class _PyTorchWrapper:
    pytorch_model: Incomplete
    def __init__(self, pytorch_model) -> None: ...
    def predict(self, data, device: str = 'cpu'): ...

def log_state_dict(state_dict, artifact_path, **kwargs) -> None: ...
def save_state_dict(state_dict, path, **kwargs) -> None: ...
def load_state_dict(state_dict_uri, **kwargs): ...
def autolog(log_every_n_epoch: int = 1, log_every_n_step: Incomplete | None = None, log_models: bool = True, disable: bool = False, exclusive: bool = False, disable_for_unsupported_versions: bool = False, silent: bool = False, registered_model_name: Incomplete | None = None) -> None: ...
