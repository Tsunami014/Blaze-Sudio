import abc
from _typeshed import Incomplete
from mlflow.exceptions import MlflowException as MlflowException
from mlflow.pipelines.artifacts import DataframeArtifact as DataframeArtifact
from mlflow.pipelines.cards import BaseCard as BaseCard
from mlflow.pipelines.step import BaseStep as BaseStep, StepClass as StepClass
from mlflow.pipelines.steps.ingest.datasets import CustomDataset as CustomDataset, DeltaTableDataset as DeltaTableDataset, ParquetDataset as ParquetDataset, SparkSqlDataset as SparkSqlDataset
from mlflow.pipelines.utils.step import get_pandas_data_profiles as get_pandas_data_profiles
from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE as INVALID_PARAMETER_VALUE
from mlflow.utils.file_utils import read_parquet_as_pandas_df as read_parquet_as_pandas_df
from typing import Any

class BaseIngestStep(BaseStep, metaclass=abc.ABCMeta): ...

class IngestStep(BaseIngestStep):
    dataset_output_name: Incomplete
    def __init__(self, step_config: dict[str, Any], pipeline_root: str) -> None: ...
    @classmethod
    def from_pipeline_config(cls, pipeline_config: dict[str, Any], pipeline_root: str): ...
    @property
    def name(self) -> str: ...
    def get_artifacts(self): ...
    def step_class(self): ...

class IngestScoringStep(BaseIngestStep):
    dataset_output_name: Incomplete
    def __init__(self, step_config: dict[str, Any], pipeline_root: str) -> None: ...
    @classmethod
    def from_pipeline_config(cls, pipeline_config: dict[str, Any], pipeline_root: str): ...
    @property
    def name(self) -> str: ...
    def get_artifacts(self): ...
    def step_class(self): ...
